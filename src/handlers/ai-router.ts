/**
 * AI Router - Jarvisã®å¸ä»¤å¡”
 *
 * ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã§æœ€é©ãªAIã‚’é¸æŠã—ã€å®Ÿè¡Œã™ã‚‹
 *
 * å¯¾å¿œãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹:
 * - "gpt: " â†’ Codex CLI (ChatGPT)
 * - "gemini: " â†’ Gemini API
 * - "croppy: " â†’ Claude CLI
 * - "all: " â†’ 3ã¤å…¨éƒ¨ã«æŠ•ã’ã¦çµ±åˆ
 * - "council: " â†’ AI Councilï¼ˆ3ã¤ã®AIã«è«®å• â†’ JarvisãŒçµ±åˆåˆ¤æ–­ï¼‰
 *
 * ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãªã— â†’ Jarvis (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
 */

export type AIProvider = 'jarvis' | 'gpt' | 'gemini' | 'croppy' | 'all' | 'council';

export interface RouteResult {
  provider: AIProvider;
  prompt: string; // ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’é™¤ã„ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
}

/**
 * AIãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®è¡¨ç¤ºåã‚’å–å¾—
 */
export function getAIDisplayName(provider: AIProvider): string {
  switch (provider) {
    case 'jarvis':
      return 'JarvisğŸ¤–';
    case 'gpt':
      return 'ãƒãƒ£ãƒƒãƒ”ãƒ¼ğŸ§ ';
    case 'gemini':
      return 'ã‚¸ã‚§ãƒŸãƒ¼ğŸ’';
    case 'croppy':
      return 'ã‚¯ãƒ­ãƒƒãƒ”ãƒ¼ğŸ¦';
    case 'all':
      return 'ğŸŒŸ All AIs';
    case 'council':
      return 'ğŸ›ï¸ AI Council';
    default:
      return 'Unknown AI';
  }
}

export interface AIResponse {
  provider: AIProvider;
  content: string;
  error?: string;
}

/**
 * Memory Gateway URL
 */
const MEMORY_GATEWAY_URL = process.env.MEMORY_GATEWAY_URL || 'https://jarvis-memory-gateway.jarvis-matsuoka.workers.dev';
const GATEWAY_API_KEY = process.env.GATEWAY_API_KEY || '';

/**
 * Memory Gatewayã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
 */
export async function callMemoryGateway(
  path: string,
  method: string,
  body?: any
): Promise<{ error?: string; data?: any }> {
  try {
    const response = await fetch(`${MEMORY_GATEWAY_URL}${path}`, {
      method,
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${GATEWAY_API_KEY}`,
      },
      body: body ? JSON.stringify(body) : undefined,
    });

    if (!response.ok) {
      return { error: `HTTP ${response.status}: ${response.statusText}` };
    }

    const data = await response.json();
    return { data };
  } catch (error: any) {
    return { error: error.message };
  }
}

export interface AICouncilResponse {
  provider: 'council';
  advisorResponses: string;
  fullResponses: Array<AIResponse>;
}

/**
 * ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’æ¤œå‡ºã—ã€AIã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åˆ†é›¢
 */
export function parseRoutePrefix(message: string): RouteResult {
  const trimmed = message.trim();

  // ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ã‚’åŒºåˆ¥ã—ãªã„ï¼‰
  const patterns: Array<{ regex: RegExp; provider: AIProvider }> = [
    { regex: /^gpt:\s*/i, provider: 'gpt' },
    { regex: /^gemini:\s*/i, provider: 'gemini' },
    { regex: /^croppy:\s*/i, provider: 'croppy' },
    { regex: /^all:\s*/i, provider: 'all' },
    { regex: /^council:\s*/i, provider: 'council' },
  ];

  for (const { regex, provider } of patterns) {
    if (regex.test(trimmed)) {
      const prompt = trimmed.replace(regex, '').trim();
      return { provider, prompt };
    }
  }

  // ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãªã— â†’ Jarvisï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
  return { provider: 'jarvis', prompt: trimmed };
}

/**
 * AI_MEMORYã‚’å–å¾—ï¼ˆè¦ç´„ç‰ˆï¼‰
 */
export async function getMemoryPack(
  credentialsPath: string,
  documentId: string
): Promise<string> {
  try {
    // èªè¨¼æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    const credentialsFile = Bun.file(credentialsPath);
    const exists = await credentialsFile.exists();
    if (!exists) {
      const errorMsg = `èªè¨¼æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: ${credentialsPath}`;
      console.error('[AI Router]', errorMsg);
      return `(AI_MEMORYå–å¾—å¤±æ•—: ${errorMsg})`;
    }

    const { getDocsClient } = await import('./gemini-tasks-sync');
    const docsClient = await getDocsClient(credentialsPath);

    const doc = await docsClient.documents.get({ documentId });

    let content = '';
    for (const element of doc.data.body?.content || []) {
      if (element.paragraph) {
        for (const textElement of element.paragraph.elements || []) {
          if (textElement.textRun) {
            content += textElement.textRun.content;
          }
        }
      }
    }

    console.log(`[AI Router] AI_MEMORY retrieved: ${content.length} chars`);

    // é•·ã™ãã‚‹å ´åˆã¯è¦ç´„ï¼ˆä»Šå¾Œå¼·åŒ–äºˆå®šï¼‰
    if (content.length > 5000) {
      const lines = content.split('\n');
      const summary = lines.slice(0, 100).join('\n'); // æœ€åˆã®100è¡Œ
      return summary + '\n\n...(ä»¥ä¸‹çœç•¥)';
    }

    return content;
  } catch (error: any) {
    const errorMsg = error?.message || String(error);
    console.error('[AI Router] Failed to get AI_MEMORY:', errorMsg);
    if (error?.status === 404) {
      return `(AI_MEMORYå–å¾—å¤±æ•—: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Doc ID: ${documentId})`;
    }
    return `(AI_MEMORYå–å¾—å¤±æ•—: ${errorMsg})`;
  }
}

/**
 * å­ãƒ—ãƒ­ã‚»ã‚¹ã‚’éåŒæœŸã§å®Ÿè¡Œï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç®¡ç†ä»˜ãï¼‰
 */
async function execAsync(
  command: string,
  args: string[],
  options: { timeout: number; cwd: string }
): Promise<string> {
  const { spawn } = await import('child_process');

  console.log('[execAsync] Starting process:', command);
  console.log('[execAsync] Args count:', args.length);
  console.log('[execAsync] Timeout:', options.timeout);
  console.log('[execAsync] CWD:', options.cwd);

  return new Promise((resolve, reject) => {
    console.log('[execAsync] Creating spawn process...');
    const proc = spawn(command, args, {
      cwd: options.cwd,
      shell: true,
      env: { ...process.env, PATH: '/usr/local/bin:/usr/bin:/bin:/opt/homebrew/bin:' + (process.env.PATH || '') },
    });

    console.log('[execAsync] Process spawned, PID:', proc.pid);

    let stdout = '';
    let stderr = '';
    let timedOut = false;

    const timer = setTimeout(() => {
      console.log('[execAsync] âš ï¸ TIMEOUT! Killing process...');
      timedOut = true;
      proc.kill('SIGKILL');
    }, options.timeout);

    proc.stdout?.on('data', (data) => {
      const chunk = data.toString();
      console.log('[execAsync] stdout chunk received, length:', chunk.length);
      stdout += chunk;
    });

    proc.stderr?.on('data', (data) => {
      const chunk = data.toString();
      console.log('[execAsync] stderr chunk received:', chunk.slice(0, 200));
      stderr += chunk;
    });

    proc.on('close', (code) => {
      console.log('[execAsync] Process closed, code:', code);
      clearTimeout(timer);
      if (timedOut) {
        reject(new Error(`Process timed out after ${options.timeout}ms`));
      } else if (code !== 0) {
        reject(new Error(`Process exited with code ${code}: ${stderr}`));
      } else {
        console.log('[execAsync] Success! stdout length:', stdout.length);
        resolve(stdout);
      }
    });

    proc.on('error', (err) => {
      console.log('[execAsync] Process error event:', err.message);
      clearTimeout(timer);
      reject(err);
    });

    console.log('[execAsync] Event listeners attached, waiting for completion...');
  });
}

/**
 * Claude CLI ã§ã‚¯ãƒ­ãƒƒãƒ”ãƒ¼ğŸ¦ã‚’å‘¼ã³å‡ºã—
 *
 * @param prompt ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆæ–‡è„ˆæ³¨å…¥æ¸ˆã¿ã®å ´åˆã‚‚ã‚ã‚Šï¼‰
 * @param memoryPack AI_MEMORYï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
 * @param skipContext æ–‡è„ˆã‚’æ—¢ã«æ³¨å…¥æ¸ˆã¿ã®å ´åˆã¯true
 * @param userId Telegram user IDï¼ˆjarvis_context + chat_historyå–å¾—ç”¨ï¼‰
 */
export async function callClaudeCLI(
  prompt: string,
  memoryPack: string,
  skipContext: boolean = false,
  userId?: string | number
): Promise<AIResponse> {
  try {
    console.log('[AI Router] ğŸ¦ Calling Claude CLI...');
    console.log('[AI Router] ğŸ¦ memoryPack length:', memoryPack.length);
    console.log('[AI Router] ğŸ¦ memoryPack preview:', memoryPack.slice(0, 200));
    console.log('[AI Router] ğŸ¦ userId:', userId);

    // AGENTS.mdï¼ˆCLAUDE.mdï¼‰ã‚’ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‹ã‚‰å–å¾—
    const { AGENTS_MD_CONTENT } = await import('../index');

    // jarvis_context ã¨ chat_history ã‚’å–å¾—
    let jarvisContext: any = null;
    let chatHistory: any[] = [];

    if (userId && !skipContext) {
      const { getJarvisContext } = await import('../utils/jarvis-context');
      const { getChatHistory } = await import('../utils/chat-history');

      jarvisContext = await getJarvisContext(userId);
      chatHistory = await getChatHistory(userId, 50); // ç›´è¿‘50ä»¶

      console.log('[AI Router] ğŸ¦ Context loaded:', {
        hasContext: !!jarvisContext,
        historyCount: chatHistory.length,
      });
    } else {
      console.log('[AI Router] ğŸ¦ Context skipped (userId:', userId, 'skipContext:', skipContext, ')');
    }

    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æƒ…å ±ï¼ˆå–å¾—å¤±æ•—æ™‚ã«å¿…ãšå«ã‚ã‚‹ï¼‰
    const fallbackInfo = `
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: ~/claude-telegram-bot
å¾“é‡èª²é‡‘APIç¦æ­¢ï¼ˆANTHROPIC_API_KEY, OPENAI_API_KEYä½¿ç”¨ç¦æ­¢ï¼‰
`.trim();

    // æ–‡è„ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰
    const { formatContextForPrompt } = await import('../utils/jarvis-context');
    const { formatChatHistoryForPrompt } = await import('../utils/chat-history');

    const formattedContext = jarvisContext
      ? formatContextForPrompt(jarvisContext)
      : 'ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãªã—ï¼‰';

    const formattedHistory = chatHistory.length > 0
      ? formatChatHistoryForPrompt(chatHistory)
      : 'ï¼ˆä¼šè©±å±¥æ­´ãªã—ï¼‰';

    // [SYSTEM] ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ§‹ç¯‰ - å¿…ãšãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æƒ…å ±ã€AGENTS.mdã€jarvis_contextã€chat_historyã‚’å«ã‚ã‚‹
    const systemBlock = `
[SYSTEM - ä»¥ä¸‹ã®æƒ…å ±ã‚’å¿…ãšæœ€åˆã«èª­ã¿ã€å…¨ã¦ã®å¿œç­”ã«åæ˜ ã™ã‚‹ã“ã¨]
${fallbackInfo}

${AGENTS_MD_CONTENT ? `# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¬ã‚¤ãƒ‰ï¼ˆæ—¢çŸ¥ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—å¯ï¼‰\n${AGENTS_MD_CONTENT}\n` : ''}
# ç¾åœ¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
${formattedContext}

# ç›´è¿‘ã®ä¼šè©±ï¼ˆ10ä»¶ï¼‰
${formattedHistory}
[END SYSTEM]
`.trim();

    const systemPrompt = `ã‚ãªãŸã¯ã‚¯ãƒ­ãƒƒãƒ”ãƒ¼ğŸ¦ï¼ˆCroppyï¼‰ã§ã™ã€‚

${systemBlock}

AI_MEMORYã®å†…å®¹ã‚’å‚ç…§ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

## AI_MEMORY
${memoryPack}

é‡è¦ãªæƒ…å ±ãŒã‚ã‚Œã°ã€å¿œç­”ã®æœ€å¾Œã«ã€Œ[MEMORY]ã€ã‚¿ã‚°ã§è¿½è¨˜å†…å®¹ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚

ä¾‹:
å¿œç­”å†…å®¹...

[MEMORY] è¿½è¨˜ã—ãŸã„é‡è¦ãªæƒ…å ±`;

    // ãƒ•ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
    const fullPrompt = `${systemPrompt}\n\n${prompt}`;

    console.log('[AI Router] ğŸ¦ Full prompt length:', fullPrompt.length);
    console.log('[AI Router] ğŸ¦ Executing via temp file (safer than pipe)...');
    const startTime = Date.now();

    // Use temp file instead of echo pipe (avoids escaping issues)
    const fs = await import('fs/promises');
    const path = await import('path');
    const { exec } = await import('child_process');
    const { promisify } = await import('util');
    const execPromise = promisify(exec);

    const tempFile = path.join('/tmp', `claude-prompt-${Date.now()}.txt`);

    try {
      // Write prompt to temp file
      await fs.writeFile(tempFile, fullPrompt, 'utf-8');

      // Execute claude with file input
      const { stdout, stderr } = await execPromise(
        `claude --model claude-opus-4-6 --print < ${tempFile}`,
        {
          timeout: 180000, // 180ç§’ï¼ˆ3åˆ†ï¼‰- ã‚¯ãƒ­ãƒƒãƒ”ãƒ¼ğŸ¦ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ”¹å–„
          cwd: '/Users/daijiromatsuokam1',
          env: { ...process.env, PATH: '/usr/local/bin:/usr/bin:/bin:/opt/homebrew/bin:' + (process.env.PATH || '') },
          maxBuffer: 10 * 1024 * 1024, // 10MB
        }
      );

      console.log(`[AI Router] ğŸ¦ Claude CLI completed in ${Date.now() - startTime}ms`);
      console.log('[AI Router] ğŸ¦ Output length:', stdout.length);
      console.log('[AI Router] ğŸ¦ Output preview:', stdout.slice(0, 200));

      if (stderr) {
        console.log('[AI Router] ğŸ¦ stderr:', stderr);
      }

      return {
        provider: 'croppy',
        content: stdout.trim(),
      };
    } finally {
      // Clean up temp file
      try {
        await fs.unlink(tempFile);
      } catch (e) {
        // Ignore cleanup errors
      }
    }
  } catch (error: any) {
    console.error('[AI Router] ğŸ¦ Claude CLI error:', error.message);
    console.error('[AI Router] ğŸ¦ Error stack:', error.stack);
    return {
      provider: 'croppy',
      content: '',
      error: `Claude CLI error: ${error.message}`,
    };
  }
}

/**
 * Gemini API ã‚’å‘¼ã³å‡ºã—
 */
export async function callGeminiAPI(
  prompt: string,
  memoryPack: string
): Promise<AIResponse> {
  try {
    console.log('[AI Router] ğŸ”® Calling Gemini API...');
    console.log('[AI Router] ğŸ”® memoryPack length:', memoryPack.length);
    console.log('[AI Router] ğŸ”® memoryPack preview:', memoryPack.slice(0, 200));
    console.log('[AI Router DEBUG] process.env.GEMINI_API_KEY:', process.env.GEMINI_API_KEY ? `${process.env.GEMINI_API_KEY.slice(0, 10)}...` : 'NOT FOUND');

    const { GoogleGenerativeAI } = await import('@google/generative-ai');

    const apiKey = process.env.GEMINI_API_KEY;
    console.log('[AI Router DEBUG] apiKey after assignment:', apiKey ? `${apiKey.slice(0, 10)}...` : 'NOT FOUND');

    if (!apiKey) {
      console.error('[AI Router DEBUG] GEMINI_API_KEY is missing!');
      return {
        provider: 'gemini',
        content: '',
        error: 'GEMINI_API_KEY is not set',
      };
    }

    console.log('[AI Router DEBUG] Creating GoogleGenerativeAI instance...');

    const genAI = new GoogleGenerativeAI(apiKey);
    console.log('[AI Router DEBUG] GoogleGenerativeAI instance created');

    const model = genAI.getGenerativeModel({
      model: 'gemini-2.5-flash',
      tools: [{ googleSearchRetrieval: {} } as any],
    });
    console.log('[AI Router DEBUG] Model created (gemini-2.5-flash + Google Search)');

    const systemPrompt = `ã‚ãªãŸã¯ã‚¸ã‚§ãƒŸãƒ¼ğŸ’ï¼ˆGemmyï¼‰ã§ã™ã€‚

AI_MEMORYã®å†…å®¹ã‚’å‚ç…§ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

## AI_MEMORY
${memoryPack}

é‡è¦ãªæƒ…å ±ãŒã‚ã‚Œã°ã€å¿œç­”ã®æœ€å¾Œã«ã€Œ[MEMORY]ã€ã‚¿ã‚°ã§è¿½è¨˜å†…å®¹ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚

ä¾‹:
å¿œç­”å†…å®¹...

[MEMORY] è¿½è¨˜ã—ãŸã„é‡è¦ãªæƒ…å ±`;

    console.log('[AI Router DEBUG] Sending request to Gemini API...');
    const result = await model.generateContent(systemPrompt + '\n\n' + prompt);
    console.log('[AI Router DEBUG] Response received from Gemini API');

    const response = await result.response;
    const text = response.text();
    console.log('[AI Router DEBUG] Response text extracted, length:', text.length);

    return {
      provider: 'gemini',
      content: text,
    };
  } catch (error: any) {
    console.error('[AI Router] Gemini API error:', error);
    console.error('[AI Router DEBUG] Error type:', error.constructor.name);
    console.error('[AI Router DEBUG] Error message:', error.message);
    console.error('[AI Router DEBUG] Full error object:', JSON.stringify(error, null, 2));

    // ã‚¨ãƒ©ãƒ¼ã®è©³ç´°æƒ…å ±ã‚’å«ã‚ã¦Telegramã«è¿”ã™ï¼ˆãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼‰
    const errorDetails = `
ğŸ”® Gemini API Error Debug Info

Error Type: ${error.constructor.name}
Error Message: ${error.message}

Stack Trace:
${error.stack || 'N/A'}

Full Error Object:
${JSON.stringify(error, null, 2)}

Environment Check:
- GEMINI_API_KEY: ${process.env.GEMINI_API_KEY ? `Set (${process.env.GEMINI_API_KEY.slice(0, 10)}...)` : 'NOT SET'}
    `.trim();

    return {
      provider: 'gemini',
      content: errorDetails,
      error: `Gemini API error: ${error.message}`,
    };
  }
}

/**
 * Codex CLI ã§ChatGPTã‚’å‘¼ã³å‡ºã—
 */
export async function callCodexCLI(
  prompt: string,
  memoryPack: string
): Promise<AIResponse> {
  try {
    console.log('[AI Router] ğŸ¤– Calling Codex CLI...');
    console.log('[AI Router] ğŸ¤– memoryPack length:', memoryPack.length);
    console.log('[AI Router] ğŸ¤– memoryPack preview:', memoryPack.slice(0, 200));

    const systemPrompt = `ã‚ãªãŸã¯ãƒãƒ£ãƒƒãƒ”ãƒ¼ğŸ§ ï¼ˆChappyï¼‰ã§ã™ã€‚

AI_MEMORYã®å†…å®¹ã‚’å‚ç…§ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

## AI_MEMORY
${memoryPack}

é‡è¦ãªæƒ…å ±ãŒã‚ã‚Œã°ã€å¿œç­”ã®æœ€å¾Œã«ã€Œ[MEMORY]ã€ã‚¿ã‚°ã§è¿½è¨˜å†…å®¹ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚

ä¾‹:
å¿œç­”å†…å®¹...

[MEMORY] è¿½è¨˜ã—ãŸã„é‡è¦ãªæƒ…å ±`;

    // ãƒ•ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
    const fullPrompt = `${systemPrompt}\n\n${prompt}`;

    console.log('[AI Router] ğŸ¤– Full prompt length:', fullPrompt.length);
    console.log('[AI Router] ğŸ¤– Executing via temp file (safer than pipe)...');
    const startTime = Date.now();

    // Use temp file instead of echo pipe (avoids escaping issues)
    const fs = await import('fs/promises');
    const path = await import('path');
    const { exec } = await import('child_process');
    const { promisify } = await import('util');
    const execPromise = promisify(exec);

    const codexPath = '/Users/daijiromatsuokam1/claude-telegram-bot/node_modules/.bin/codex';
    const tempFile = path.join('/tmp', `codex-prompt-${Date.now()}.txt`);

    try {
      // Write prompt to temp file
      await fs.writeFile(tempFile, fullPrompt, 'utf-8');

      // Execute codex with file input
      const { stdout, stderr } = await execPromise(
        `${codexPath} exec --skip-git-repo-check < ${tempFile}`,
        {
          timeout: 180000, // 180ç§’ï¼ˆ3åˆ†ï¼‰- ãƒãƒ£ãƒƒãƒ”ãƒ¼ğŸ§ ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ”¹å–„
          cwd: '/Users/daijiromatsuokam1',
          env: { ...process.env, PATH: '/usr/local/bin:/usr/bin:/bin:/opt/homebrew/bin:' + (process.env.PATH || '') },
          maxBuffer: 10 * 1024 * 1024, // 10MB
        }
      );

      console.log(`[AI Router] ğŸ¤– Codex CLI completed in ${Date.now() - startTime}ms`);
      console.log('[AI Router] ğŸ¤– Output length:', stdout.length);
      console.log('[AI Router] ğŸ¤– Output preview:', stdout.slice(0, 200));

      if (stderr) {
        console.log('[AI Router] ğŸ¤– stderr:', stderr);
      }

      return {
        provider: 'gpt',
        content: stdout.trim(),
      };
    } finally {
      // Clean up temp file
      try {
        await fs.unlink(tempFile);
      } catch (e) {
        // Ignore cleanup errors
      }
    }
  } catch (error: any) {
    console.error('[AI Router] ğŸ¤– Codex CLI error:', error.message);
    console.error('[AI Router] ğŸ¤– Error stack:', error.stack);
    return {
      provider: 'gpt',
      content: '',
      error: `Codex CLI error: ${error.message}`,
    };
  }
}

/**
 * ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šæ–‡å­—æ•°ã§åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆæ–‡ã®é€”ä¸­ã§åˆ‡ã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹ï¼‰
 */
function truncateText(text: string, maxLength: number): string {
  if (text.length <= maxLength) {
    return text;
  }

  // maxLengthã‚ˆã‚Šæ‰‹å‰ã§æœ€å¾Œã®æ”¹è¡Œã¾ãŸã¯å¥ç‚¹ã‚’æ¢ã™
  const truncated = text.slice(0, maxLength);
  const lastBreak = Math.max(
    truncated.lastIndexOf('\n'),
    truncated.lastIndexOf('ã€‚'),
    truncated.lastIndexOf('. ')
  );

  if (lastBreak > maxLength * 0.5) {
    return truncated.slice(0, lastBreak + 1) + '\n...(çœç•¥)';
  }

  return truncated + '...(çœç•¥)';
}

/**
 * 3ã¤ã®AIå…¨éƒ¨ã«æŠ•ã’ã¦çµ±åˆ
 */
export async function callAllAIs(
  prompt: string,
  memoryPack: string,
  userId?: string | number
): Promise<AIResponse> {
  console.log('[AI Router] ğŸŒŸ Calling all AIs...');
  console.log('[AI Router] ğŸŒŸ memoryPack for all AIs:');
  console.log('[AI Router] ğŸŒŸ   - length:', memoryPack.length);
  console.log('[AI Router] ğŸŒŸ   - preview:', memoryPack.slice(0, 300));
  console.log('[AI Router] ğŸŒŸ   - contains error?:', memoryPack.includes('å–å¾—å¤±æ•—'));
  console.log('[AI Router] ğŸŒŸ   - full memoryPack:', memoryPack);

  // å„AIå¿œç­”ã®æœ€å¤§æ–‡å­—æ•°
  const MAX_RESPONSE_LENGTH = 500;

  // é †æ¬¡å®Ÿè¡Œï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ - ä¸¦åˆ—ã ã¨ã©ã“ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‹åˆ†ã‹ã‚‰ãªã„ï¼‰
  console.log('[AI Router] ğŸŒŸ Starting Gemini first (fastest)...');
  console.log('[AI Router] ğŸŒŸ Passing memoryPack to Gemini:', { length: memoryPack.length, hasError: memoryPack.includes('å–å¾—å¤±æ•—') });
  const geminiResponse = await callGeminiAPI(prompt, memoryPack);
  console.log('[AI Router] ğŸŒŸ Gemini done, result:', geminiResponse.error ? `ERROR: ${geminiResponse.error}` : 'OK');

  console.log('[AI Router] ğŸŒŸ Starting Claude CLI...');
  const claudeResponse = await callClaudeCLI(prompt, memoryPack, false, userId);
  console.log('[AI Router] ğŸŒŸ Claude done, result:', claudeResponse.error ? `ERROR: ${claudeResponse.error}` : 'OK');

  console.log('[AI Router] ğŸŒŸ Starting Codex CLI...');
  const gptResponse = await callCodexCLI(prompt, memoryPack);
  console.log('[AI Router] ğŸŒŸ Codex done, result:', gptResponse.error ? `ERROR: ${gptResponse.error}` : 'OK');

  // çµ±åˆçµæœã‚’ä½œæˆï¼ˆå„å¿œç­”ã‚’500æ–‡å­—ã«åˆ‡ã‚Šè©°ã‚ï¼‰
  let combined = 'ğŸŒŸ **All AIs Response**\n\n';

  if (claudeResponse.content) {
    const truncated = truncateText(claudeResponse.content, MAX_RESPONSE_LENGTH);
    combined += `## ã‚¯ãƒ­ãƒƒãƒ”ãƒ¼ğŸ¦\n${truncated}\n\n`;
  } else if (claudeResponse.error) {
    combined += `## ã‚¯ãƒ­ãƒƒãƒ”ãƒ¼ğŸ¦\nâš ï¸ ${claudeResponse.error}\n\n`;
  }

  if (geminiResponse.content) {
    const truncated = truncateText(geminiResponse.content, MAX_RESPONSE_LENGTH);
    combined += `## ã‚¸ã‚§ãƒŸãƒ¼ğŸ’\n${truncated}\n\n`;
  } else if (geminiResponse.error) {
    combined += `## ã‚¸ã‚§ãƒŸãƒ¼ğŸ’\nâš ï¸ ${geminiResponse.error}\n\n`;
  }

  if (gptResponse.content) {
    const truncated = truncateText(gptResponse.content, MAX_RESPONSE_LENGTH);
    combined += `## ãƒãƒ£ãƒƒãƒ”ãƒ¼ğŸ§ \n${truncated}\n\n`;
  } else if (gptResponse.error) {
    combined += `## ãƒãƒ£ãƒƒãƒ”ãƒ¼ğŸ§ \nâš ï¸ ${gptResponse.error}\n\n`;
  }

  return {
    provider: 'all',
    content: combined,
  };
}

/**
 * AI Council - 3ã¤ã®AIã«è«®å•ã—ã¦JarvisãŒçµ±åˆåˆ¤æ–­
 */
export async function callAICouncil(
  prompt: string,
  memoryPack: string
): Promise<Omit<AICouncilResponse, 'provider'>> {
  console.log('[AI Council] ğŸ›ï¸ Calling AI Council...');
  console.log('[AI Council] ğŸ›ï¸ memoryPack length:', memoryPack.length);

  // 3ã¤ã®AIã«ä¸¦è¡Œã§è«®å•ï¼ˆå€‹åˆ¥ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
  console.log('[AI Council] ğŸ›ï¸ Consulting advisors in parallel with individual error handling...');

  // å„AIã‚’å€‹åˆ¥ã«try-catchã§ãƒ©ãƒƒãƒ— + 10ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
  const callWithFallback = async (
    fn: () => Promise<AIResponse>,
    providerName: string
  ): Promise<AIResponse> => {
    console.log(`[AI Council] ğŸ›ï¸ Starting ${providerName} call...`);
    const startTime = Date.now();

    try {
      // 210ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆå€‹åˆ¥AIå‘¼ã³å‡ºã—180ç§’ + ãƒãƒƒãƒ•ã‚¡30ç§’ï¼‰
      const timeoutPromise = new Promise<AIResponse>((_, reject) =>
        setTimeout(() => reject(new Error('COUNCIL_TIMEOUT')), 210000)
      );

      const result = await Promise.race([fn(), timeoutPromise]);

      const duration = Date.now() - startTime;
      console.log(`[AI Council] ğŸ›ï¸ ${providerName} completed in ${duration}ms`);
      return result;
    } catch (error: any) {
      const duration = Date.now() - startTime;

      if (error.message === 'COUNCIL_TIMEOUT') {
        console.error(`[AI Council] COUNCIL_TIMEOUT: ${providerName} (${duration}ms)`);
        return {
          provider: providerName.toLowerCase() as any,
          content: '',
          error: `âš ï¸ Timeout (210s exceeded)`,
        };
      }

      console.error(`[AI Council] ${providerName} failed in ${duration}ms:`, error.message);
      return {
        provider: providerName.toLowerCase() as any,
        content: '',
        error: error.message || 'Unknown error',
      };
    }
  };

  // ä¸¦è¡Œå®Ÿè¡Œï¼ˆå„AIã®ã‚¨ãƒ©ãƒ¼ã¯å€‹åˆ¥ã«ã‚­ãƒ£ãƒƒãƒï¼‰
  const [geminiResponse, claudeResponse, gptResponse] = await Promise.all([
    callWithFallback(() => callGeminiAPI(prompt, memoryPack), 'Gemini'),
    callWithFallback(() => callClaudeCLI(prompt, memoryPack), 'Claude'),
    callWithFallback(() => callCodexCLI(prompt, memoryPack), 'GPT'),
  ]);

  console.log('[AI Council] ğŸ›ï¸ All advisors responded (some may have errors)');
  console.log('[AI Council] ğŸ›ï¸ Gemini:', geminiResponse.error ? `Error: ${geminiResponse.error}` : 'OK');
  console.log('[AI Council] ğŸ›ï¸ Claude:', claudeResponse.error ? `Error: ${claudeResponse.error}` : 'OK');
  console.log('[AI Council] ğŸ›ï¸ GPT:', gptResponse.error ? `Error: ${gptResponse.error}` : 'OK');

  // ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã®å¿œç­”ã‚’ã¾ã¨ã‚ã‚‹
  let advisorResponses = '## AI Council Advisors\n\n';

  if (claudeResponse.content) {
    advisorResponses += `### ã‚¯ãƒ­ãƒƒãƒ”ãƒ¼ğŸ¦ã®æ„è¦‹\n${claudeResponse.content}\n\n`;
  } else if (claudeResponse.error) {
    advisorResponses += `### ã‚¯ãƒ­ãƒƒãƒ”ãƒ¼ğŸ¦ã®æ„è¦‹\nâš ï¸ ${claudeResponse.error}\n\n`;
  }

  if (geminiResponse.content) {
    advisorResponses += `### ã‚¸ã‚§ãƒŸãƒ¼ğŸ’ã®æ„è¦‹\n${geminiResponse.content}\n\n`;
  } else if (geminiResponse.error) {
    advisorResponses += `### ã‚¸ã‚§ãƒŸãƒ¼ğŸ’ã®æ„è¦‹\nâš ï¸ ${geminiResponse.error}\n\n`;
  }

  if (gptResponse.content) {
    advisorResponses += `### ãƒãƒ£ãƒƒãƒ”ãƒ¼ğŸ§ ã®æ„è¦‹\n${gptResponse.content}\n\n`;
  } else if (gptResponse.error) {
    advisorResponses += `### ãƒãƒ£ãƒƒãƒ”ãƒ¼ğŸ§ ã®æ„è¦‹\nâš ï¸ ${gptResponse.error}\n\n`;
  }

  return {
    advisorResponses,
    fullResponses: [geminiResponse, claudeResponse, gptResponse],
  };
}

/**
 * AIãƒ«ãƒ¼ã‚¿ãƒ¼ - ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
 */
export async function routeToAI(
  provider: AIProvider,
  prompt: string,
  credentialsPath: string,
  documentId: string
): Promise<AIResponse | AICouncilResponse> {
  console.log(`[AI Router] Routing to: ${provider}`);

  // 1. Memory Packå–å¾—
  const memoryPack = await getMemoryPack(credentialsPath, documentId);

  // 2. AIå®Ÿè¡Œ
  switch (provider) {
    case 'croppy':
      return callClaudeCLI(prompt, memoryPack);

    case 'gemini':
      return callGeminiAPI(prompt, memoryPack);

    case 'gpt':
      return callCodexCLI(prompt, memoryPack);

    case 'all':
      return callAllAIs(prompt, memoryPack);

    case 'council':
      const councilResult = await callAICouncil(prompt, memoryPack);
      return {
        provider: 'council',
        ...councilResult,
      };

    case 'jarvis':
    default:
      // Jarvisï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ã¯å‘¼ã³å‡ºã—å…ƒã§å‡¦ç†
      return {
        provider: 'jarvis',
        content: '',
      };
  }
}

/**
 * AIå¿œç­”ã‹ã‚‰MEMORYã‚¿ã‚°ã‚’æŠ½å‡ºã—ã¦AI_MEMORYã«è¿½è¨˜
 */
export async function extractAndSaveMemory(
  response: AIResponse,
  credentialsPath: string,
  documentId: string
): Promise<void> {
  const memoryMatch = response.content.match(/\[MEMORY\]\s*(.+?)(?:\n|$)/s);

  if (!memoryMatch) {
    return; // MEMORYã‚¿ã‚°ãªã—
  }

  const memoryContent = memoryMatch[1]!.trim();

  if (!memoryContent) {
    return;
  }

  try {
    const { getDocsClient } = await import('./gemini-tasks-sync');
    const docsClient = await getDocsClient(credentialsPath);

    const doc = await docsClient.documents.get({ documentId });
    const bodyContent = doc.data.body?.content;
    const endIndex = bodyContent?.[bodyContent.length - 1]?.endIndex;

    const timestamp = new Date().toISOString().split('T')[0];
    const source = response.provider === 'croppy' ? 'ã‚¯ãƒ­ãƒƒãƒ”ãƒ¼ğŸ¦' :
                   response.provider === 'gemini' ? 'ã‚¸ã‚§ãƒŸãƒ¼ğŸ’' :
                   response.provider === 'gpt' ? 'ãƒãƒ£ãƒƒãƒ”ãƒ¼ğŸ§ ' : 'AI';

    const appendText = `\n- [${timestamp}] (${source}) ${memoryContent}\n`;

    await docsClient.documents.batchUpdate({
      documentId,
      requestBody: {
        requests: [
          {
            insertText: {
              text: appendText,
              location: { index: (endIndex ?? 1) - 1 },
            },
          },
        ],
      },
    });

    console.log(`[AI Router] âœ… Saved to AI_MEMORY: ${memoryContent}`);
  } catch (error) {
    console.error('[AI Router] Failed to save memory:', error);
  }
}
